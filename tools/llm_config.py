"""
LLM Configuration Module
–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö LLM –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤
"""
import os
from typing import Dict, List, Any, Optional
from pathlib import Path
import yaml


def load_llm_tiers() -> Dict[str, Any]:
    """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ LLM —É—Ä–æ–≤–Ω–µ–π"""
    config_path = Path(__file__).parent.parent / "config" / "llm_tiers.yaml"
    
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ llm_tiers.yaml: {e}")
        return get_default_tiers()


def get_default_tiers() -> Dict[str, Any]:
    """–ë–∞–∑–æ–≤–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –µ—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"""
    return {
        "tiers": {
            "cheap": [
                {"name": "gpt-3.5-turbo", "provider": "openrouter"},
                {"name": "llama-3.1-8b-instruct", "provider": "openrouter"}
            ],
            "standard": [
                {"name": "gpt-4o-mini", "provider": "openrouter"},
                {"name": "claude-3-haiku", "provider": "openrouter"}
            ],
            "premium": [
                {"name": "gpt-4o", "provider": "openrouter"},
                {"name": "claude-3-sonnet", "provider": "openrouter"}
            ]
        },
        "max_retries": 3
    }


def create_llm_config(model_name: str = "gpt-4o-mini", provider: str = "openrouter") -> Dict[str, Any]:
    """–°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è LLM –º–æ–¥–µ–ª–∏"""
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ API –∫–ª—é—á–µ–π
    openrouter_key = os.getenv('OPENROUTER_API_KEY')
    openai_key = os.getenv('OPENAI_API_KEY')
    
    if provider == "openrouter" and openrouter_key:
        return {
            "config_list": [{
                "model": model_name,
                "api_key": openrouter_key,
                "base_url": "https://openrouter.ai/api/v1",
                "temperature": 0.7,
                "max_tokens": 2000
            }],
            "timeout": 60,
            "cache_seed": None,  # –û—Ç–∫–ª—é—á–∞–µ–º –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –±–æ–ª–µ–µ —Å–≤–µ–∂–∏—Ö –æ—Ç–≤–µ—Ç–æ–≤
        }
    
    elif provider == "openai" and openai_key:
        return {
            "config_list": [{
                "model": model_name,
                "api_key": openai_key,
                "temperature": 0.7,
                "max_tokens": 2000
            }],
            "timeout": 60,
            "cache_seed": None,
        }
    
    else:
        # Fallback –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è —Ä–µ–∂–∏–º–∞ –±–µ–∑ API
        print(f"‚ö†Ô∏è API –∫–ª—é—á –¥–ª—è {provider} –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º mock –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é")
        return {
            "config_list": [{
                "model": "mock_model",
                "api_key": "mock_key",
                "base_url": "http://localhost:8000"  # –ù–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π endpoint
            }],
            "timeout": 5,
        }


def get_model_by_tier(tier: str = "cheap", attempt: int = 0) -> Dict[str, Any]:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –ø–æ —É—Ä–æ–≤–Ω—é –∏ –ø–æ–ø—ã—Ç–∫–µ"""
    tiers_config = load_llm_tiers()
    
    tier_models = tiers_config.get("tiers", {}).get(tier, [])
    
    if not tier_models:
        # Fallback –∫ –¥–µ—à–µ–≤–æ–π –º–æ–¥–µ–ª–∏
        tier_models = tiers_config.get("tiers", {}).get("cheap", [])
    
    if attempt >= len(tier_models):
        # –ï—Å–ª–∏ –∏—Å—á–µ—Ä–ø–∞–ª–∏ –º–æ–¥–µ–ª–∏ –≤ tier, –±–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é
        model_info = tier_models[-1] if tier_models else {"name": "gpt-3.5-turbo", "provider": "openrouter"}
    else:
        model_info = tier_models[attempt]
    
    return create_llm_config(model_info["name"], model_info["provider"])


def upgrade_tier(current_tier: str) -> str:
    """–ü–æ–≤—ã—à–µ–Ω–∏–µ —É—Ä–æ–≤–Ω—è –º–æ–¥–µ–ª–∏ –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö"""
    tier_order = ["cheap", "standard", "premium"]
    
    try:
        current_index = tier_order.index(current_tier)
        if current_index < len(tier_order) - 1:
            return tier_order[current_index + 1]
    except ValueError:
        pass
    
    return "premium"  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å


def validate_api_keys() -> Dict[str, bool]:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è API –∫–ª—é—á–µ–π"""
    return {
        "openrouter": bool(os.getenv('OPENROUTER_API_KEY')),
        "openai": bool(os.getenv('OPENAI_API_KEY')),
        "yandex": bool(os.getenv('YANDEX_GPT_API_KEY')),
        "anthropic": bool(os.getenv('ANTHROPIC_API_KEY')),
    }


def get_available_models() -> List[str]:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –Ω–∞ –æ—Å–Ω–æ–≤–µ API –∫–ª—é—á–µ–π"""
    api_status = validate_api_keys()
    tiers_config = load_llm_tiers()
    
    available_models = []
    
    for tier_name, models in tiers_config.get("tiers", {}).items():
        for model in models:
            provider = model.get("provider", "openrouter")
            if api_status.get(provider, False):
                available_models.append(f"{model['name']} ({tier_name})")
    
    return available_models


if __name__ == "__main__":
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥—É–ª—è
    print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ LLM –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
    print("=" * 50)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º API –∫–ª—é—á–∏
    api_status = validate_api_keys()
    print("üîë –°—Ç–∞—Ç—É—Å API –∫–ª—é—á–µ–π:")
    for provider, available in api_status.items():
        status = "‚úÖ" if available else "‚ùå"
        print(f"  {status} {provider}")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏
    models = get_available_models()
    print(f"\nü§ñ –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ ({len(models)}):")
    for model in models:
        print(f"  ‚Ä¢ {model}")
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    print(f"\n‚öôÔ∏è –¢–µ—Å—Ç–æ–≤–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è:")
    config = get_model_by_tier("cheap", 0)
    print(f"  Model: {config['config_list'][0]['model']}")
    print(f"  Provider: {config['config_list'][0].get('base_url', 'OpenAI')}")